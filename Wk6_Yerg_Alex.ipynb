{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment is below at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://scikit-learn.org/stable/modules/tree.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20, 6)\n",
    "plt.rcParams['font.size'] = 14\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/adult.data', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden = pd.read_csv('../data/adult.test', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the following use the above `adult` dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Show the RandomForest outperforms the DecisionTree for a fixed `max_depth` by training using the train set and calculate `precision`, `recall`, `f1`, `confusion matrix` on golden-test set. Start with only numerical features/columns. (age, education-num, capital-gain, capital-loss, hours-per-week) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20, 6)\n",
    "plt.rcParams['font.size'] = 14\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, auc, roc_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "# df = training set; golden = test set\n",
    "df = pd.read_csv('../data/adult.data', index_col=False)\n",
    "golden = pd.read_csv('../data/adult.test', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inititate models and encoders\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "onehot = preprocessing.OneHotEncoder(handle_unknown=\"error\", sparse=False)\n",
    "rf_classifier = RandomForestClassifier(criterion='entropy')\n",
    "dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex_ Female  sex_ Male\n",
       "0            0          1\n",
       "1            0          1\n",
       "2            0          1\n",
       "3            0          1\n",
       "4            1          0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ID categorical variables; and Transform 'sex' to 0 or 1\n",
    "transform_columns = ['sex']\n",
    "non_num_columns = ['workclass', 'education', 'marital-status', \n",
    "                     'occupation', 'relationship', 'race', 'sex', \n",
    "                     'native-country']\n",
    "# testing\n",
    "pd.get_dummies(df[transform_columns]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SET: Remove categorical variables and encode salary\n",
    "x = df.copy()\n",
    "\n",
    "\n",
    "#x = pd.concat([x.drop(non_num_columns, axis=1), pd.get_dummies(df[transform_columns])], axis=1,)\n",
    "\n",
    "x = x.drop(non_num_columns, axis=1)\n",
    "\n",
    "x[\"salary\"] = enc.fit_transform(df[[\"salary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   salary  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING SET: Remove categorical variables and encode salary\n",
    "xt = golden.copy()\n",
    "\n",
    "#xt = pd.concat([xt.drop(non_num_columns, axis=1), pd.get_dummies(golden[transform_columns])], axis=1,)\n",
    "\n",
    "xt = xt.drop(non_num_columns, axis=1)\n",
    "\n",
    "xt[\"salary\"] = enc.fit_transform(golden[[\"salary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the models: Decision Tree & Random Forest\n",
    "dt_classifier.fit(x.drop(['salary','fnlwgt'], axis=1), x.salary)\n",
    "rf_classifier.fit(x.drop(['salary','fnlwgt'], axis=1), x.salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "pred_dt = dt_classifier.predict(xt.drop(['salary','fnlwgt'], axis=1))\n",
    "pred_rf = rf_classifier.predict(xt.drop(['salary','fnlwgt'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy Score: 0.8031447699772741\n",
      "Random Tree Accuracy Score: 0.8224924758921442\n"
     ]
    }
   ],
   "source": [
    "# Evalute Decision Tree vs. Random Forest on TEST set\n",
    "\n",
    "print(\"Decision Tree Accuracy Score:\",accuracy_score(xt.salary, pred_dt))\n",
    "print(\"Random Tree Accuracy Score:\",accuracy_score(xt.salary, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Confusion Matrix:\n",
      "[[12428     7]\n",
      " [ 3198   648]]\n",
      "Random Tree Confusion Matrix:\n",
      "[[11559   876]\n",
      " [ 2014  1832]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Confusion Matrix:\")\n",
    "print(confusion_matrix(xt.salary, pred_dt))\n",
    "print(\"Random Tree Confusion Matrix:\")\n",
    "print(confusion_matrix(xt.salary, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89     12435\n",
      "         1.0       0.99      0.17      0.29      3846\n",
      "\n",
      "    accuracy                           0.80     16281\n",
      "   macro avg       0.89      0.58      0.59     16281\n",
      "weighted avg       0.84      0.80      0.74     16281\n",
      "\n",
      "Random Tree Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.93      0.89     12435\n",
      "         1.0       0.68      0.48      0.56      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.76      0.70      0.72     16281\n",
      "weighted avg       0.81      0.82      0.81     16281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classification report:\")\n",
    "print(classification_report(xt.salary, pred_dt))\n",
    "print(\"Random Tree Classification report:\")\n",
    "print(classification_report(xt.salary, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use a RandomForest or DecisionTree and the `adult` dataset, systematically add new columns, one by one, that are non-numerical but converted using the feature-extraction techniques we learned. Using the golden-test set show [`precision`, `recall`, `f1`, `confusion matrix`] for each additional feature added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns we want to transform\n",
    "transform_columns = ['workclass', 'education', 'marital-status', \n",
    "                     'occupation', 'relationship', 'race', 'sex', \n",
    "                     'native-country']\n",
    "\n",
    "\n",
    "#Columns we can't use because non-numerical\n",
    "non_num_columns = ['workclass', 'education', 'marital-status', \n",
    "                     'occupation', 'relationship', 'race', 'sex', \n",
    "                     'native-country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for discrepancies between training and test datasets, then fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SET\n",
    "\n",
    "x = df.copy()\n",
    "\n",
    "#transformed = pd.get_dummies(x[transform_columns])\n",
    "\n",
    "#onehot = preprocessing.OneHotEncoder(handle_unknown=\"infrequent_if_exist\", sparse=False).fit(df[transform_columns])\n",
    "\n",
    "onehot = preprocessing.OneHotEncoder(drop = 'first', handle_unknown=\"ignore\", sparse=False).fit(x[transform_columns])\n",
    "\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "\n",
    "enc.fit(x[[\"salary\"]])\n",
    "\n",
    "transformed = onehot.transform(x[transform_columns])\n",
    "#new_cols = list(onehot.categories_[0].flatten())\n",
    "# Flatten all arrays in onehot.categories_\n",
    "new_cols = [category for categories in onehot.categories_ for category in categories[1:]]\n",
    "x_trans = pd.DataFrame(transformed, columns=new_cols)\n",
    "\n",
    "x = pd.concat(\n",
    "    [\n",
    "        x.drop(non_num_columns, axis=1), \n",
    "        x_trans\n",
    "    ], \n",
    "    axis=1,)\n",
    "\n",
    "x[\"salary\"] = enc.transform(x[[\"salary\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "\n",
    "xt = golden.copy()\n",
    "\n",
    "#xt_transformed = pd.get_dummies(xt[transform_columns])\n",
    "#onehot = preprocessing.OneHotEncoder(handle_unknown=\"infrequent_if_exist\", sparse=False).fit(df[transform_columns])\n",
    "\n",
    "xt_onehot = preprocessing.OneHotEncoder(drop = 'first', handle_unknown=\"ignore\", sparse=False).fit(xt[transform_columns])\n",
    "\n",
    "xt_enc = preprocessing.OrdinalEncoder()\n",
    "\n",
    "xt_enc.fit(xt[[\"salary\"]])\n",
    "\n",
    "xt_transformed = xt_onehot.transform(xt[transform_columns])\n",
    "#new_cols = list(onehot.categories_[0].flatten())\n",
    "# Flatten all arrays in onehot.categories_\n",
    "xt_new_cols = [category for categories in xt_onehot.categories_ for category in categories[1:]]\n",
    "xt_trans = pd.DataFrame(xt_transformed, columns=xt_new_cols)\n",
    "\n",
    "\n",
    "xt = pd.concat(\n",
    "    [\n",
    "        xt.drop(non_num_columns, axis=1), \n",
    "        xt_trans\n",
    "    ], \n",
    "    axis=1,)\n",
    "\n",
    "xt[\"salary\"] = xt_enc.transform(xt[[\"salary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.copy()\n",
    "#x['native-country'].unique()\n",
    "(x['native-country'] == ' Holand-Netherlands').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 101), (16281, 100))"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Holand-Netherlands'}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(x.columns)-set(xt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through the Training/Test dataset to add 1 categorical feature for each iteration, format, Fit, Transform, Predict and Evaluate the Models: Decision Tree & Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Using numerical columns and ['workclass']\n",
      "Decision Tree Accuracy Score: 0.8113752226521712\n",
      "Random Forest Accuracy Score: 0.8202198882132548\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[11378  1057]\n",
      " [ 2014  1832]]\n",
      "Random Forest Confusion Matrix:\n",
      "[[11468   967]\n",
      " [ 1960  1886]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.91      0.88     12435\n",
      "         1.0       0.63      0.48      0.54      3846\n",
      "\n",
      "    accuracy                           0.81     16281\n",
      "   macro avg       0.74      0.70      0.71     16281\n",
      "weighted avg       0.80      0.81      0.80     16281\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.92      0.89     12435\n",
      "         1.0       0.66      0.49      0.56      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.76      0.71      0.72     16281\n",
      "weighted avg       0.81      0.82      0.81     16281\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Iteration 2: Using numerical columns and ['workclass', 'education']\n",
      "Decision Tree Accuracy Score: 0.8108838523432221\n",
      "Random Forest Accuracy Score: 0.8165346108961365\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[11377  1058]\n",
      " [ 2021  1825]]\n",
      "Random Forest Confusion Matrix:\n",
      "[[11408  1027]\n",
      " [ 1960  1886]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.91      0.88     12435\n",
      "         1.0       0.63      0.47      0.54      3846\n",
      "\n",
      "    accuracy                           0.81     16281\n",
      "   macro avg       0.74      0.69      0.71     16281\n",
      "weighted avg       0.80      0.81      0.80     16281\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.92      0.88     12435\n",
      "         1.0       0.65      0.49      0.56      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.75      0.70      0.72     16281\n",
      "weighted avg       0.80      0.82      0.81     16281\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Iteration 3: Using numerical columns and ['workclass', 'education', 'marital-status']\n",
      "Decision Tree Accuracy Score: 0.8295559240832873\n",
      "Random Forest Accuracy Score: 0.8373564277378539\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[11290  1145]\n",
      " [ 1630  2216]]\n",
      "Random Forest Confusion Matrix:\n",
      "[[11328  1107]\n",
      " [ 1541  2305]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.91      0.89     12435\n",
      "         1.0       0.66      0.58      0.61      3846\n",
      "\n",
      "    accuracy                           0.83     16281\n",
      "   macro avg       0.77      0.74      0.75     16281\n",
      "weighted avg       0.82      0.83      0.83     16281\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.91      0.90     12435\n",
      "         1.0       0.68      0.60      0.64      3846\n",
      "\n",
      "    accuracy                           0.84     16281\n",
      "   macro avg       0.78      0.76      0.77     16281\n",
      "weighted avg       0.83      0.84      0.83     16281\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Iteration 4: Using numerical columns and ['workclass', 'education', 'marital-status', 'occupation']\n",
      "Decision Tree Accuracy Score: 0.8235980590872797\n",
      "Random Forest Accuracy Score: 0.8431914501566243\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[11060  1375]\n",
      " [ 1497  2349]]\n",
      "Random Forest Confusion Matrix:\n",
      "[[11356  1079]\n",
      " [ 1474  2372]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.89      0.89     12435\n",
      "         1.0       0.63      0.61      0.62      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.76      0.75      0.75     16281\n",
      "weighted avg       0.82      0.82      0.82     16281\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.91      0.90     12435\n",
      "         1.0       0.69      0.62      0.65      3846\n",
      "\n",
      "    accuracy                           0.84     16281\n",
      "   macro avg       0.79      0.76      0.77     16281\n",
      "weighted avg       0.84      0.84      0.84     16281\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Iteration 5: Using numerical columns and ['workclass', 'education', 'marital-status', 'occupation', 'relationship']\n",
      "Decision Tree Accuracy Score: 0.8202198882132548\n",
      "Random Forest Accuracy Score: 0.8435599778883361\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[11032  1403]\n",
      " [ 1524  2322]]\n",
      "Random Forest Confusion Matrix:\n",
      "[[11367  1068]\n",
      " [ 1479  2367]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.89      0.88     12435\n",
      "         1.0       0.62      0.60      0.61      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.75      0.75      0.75     16281\n",
      "weighted avg       0.82      0.82      0.82     16281\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.91      0.90     12435\n",
      "         1.0       0.69      0.62      0.65      3846\n",
      "\n",
      "    accuracy                           0.84     16281\n",
      "   macro avg       0.79      0.76      0.77     16281\n",
      "weighted avg       0.84      0.84      0.84     16281\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Iteration 6: Using numerical columns and ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
      "Decision Tree Accuracy Score: 0.8215711565628647\n",
      "Random Forest Accuracy Score: 0.8443584546403784\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[11011  1424]\n",
      " [ 1481  2365]]\n",
      "Random Forest Confusion Matrix:\n",
      "[[11389  1046]\n",
      " [ 1488  2358]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.89      0.88     12435\n",
      "         1.0       0.62      0.61      0.62      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.75      0.75      0.75     16281\n",
      "weighted avg       0.82      0.82      0.82     16281\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.92      0.90     12435\n",
      "         1.0       0.69      0.61      0.65      3846\n",
      "\n",
      "    accuracy                           0.84     16281\n",
      "   macro avg       0.79      0.76      0.78     16281\n",
      "weighted avg       0.84      0.84      0.84     16281\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Iteration 7: Using numerical columns and ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex']\n",
      "Decision Tree Accuracy Score: 0.8200970456360175\n",
      "Random Forest Accuracy Score: 0.8448498249493275\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[11002  1433]\n",
      " [ 1496  2350]]\n",
      "Random Forest Confusion Matrix:\n",
      "[[11403  1032]\n",
      " [ 1494  2352]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88     12435\n",
      "         1.0       0.62      0.61      0.62      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.75      0.75      0.75     16281\n",
      "weighted avg       0.82      0.82      0.82     16281\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.92      0.90     12435\n",
      "         1.0       0.70      0.61      0.65      3846\n",
      "\n",
      "    accuracy                           0.84     16281\n",
      "   macro avg       0.79      0.76      0.78     16281\n",
      "weighted avg       0.84      0.84      0.84     16281\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Iteration 8: Using numerical columns and ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
      "Decision Tree Accuracy Score: 0.8188071985750262\n",
      "Random Forest Accuracy Score: 0.8467538848965052\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      "[[11005  1430]\n",
      " [ 1520  2326]]\n",
      "Random Forest Confusion Matrix:\n",
      "[[11432  1003]\n",
      " [ 1492  2354]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.89      0.88     12435\n",
      "         1.0       0.62      0.60      0.61      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.75      0.74      0.75     16281\n",
      "weighted avg       0.82      0.82      0.82     16281\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.92      0.90     12435\n",
      "         1.0       0.70      0.61      0.65      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.79      0.77      0.78     16281\n",
      "weighted avg       0.84      0.85      0.84     16281\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Columns to transform and the non-numerical columns\n",
    "transform_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "non_num_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "# TRAINING SET\n",
    "x = df.copy() \n",
    "x = x[x['native-country'] != ' Holand-Netherlands'].reset_index(drop=True) # remove Holand since it doesnt exist in test set\n",
    "x['salary'] = x['salary'].str.replace('.', '').str.strip()  # Clean/standardize format of 'salary' \n",
    "\n",
    "# TEST SET\n",
    "xt = golden.copy()  \n",
    "xt['salary'] = xt['salary'].str.replace('.', '').str.strip()  \n",
    "\n",
    "# Encode target variable\n",
    "enc = OrdinalEncoder()\n",
    "x[\"salary_encoded\"] = enc.fit_transform(x[[\"salary\"]])\n",
    "xt[\"salary_encoded\"] = enc.transform(xt[[\"salary\"]])\n",
    "\n",
    "# Fit OneHotEncoder on all categorical columns\n",
    "onehot = OneHotEncoder(drop='first', handle_unknown=\"ignore\", sparse=False) \n",
    "onehot.fit(pd.concat([x[transform_columns], xt[transform_columns]], axis=0))  # Combine to ensure all categories are captured\n",
    "\n",
    "# Transform all categorical features at once for both sets\n",
    "x_transformed = pd.DataFrame(onehot.transform(x[transform_columns]), columns=onehot.get_feature_names_out(), index=x.index)\n",
    "xt_transformed = pd.DataFrame(onehot.transform(xt[transform_columns]), columns=onehot.get_feature_names_out(), index=xt.index)\n",
    "\n",
    "# Iterate over the number of categorical variables, adding one at a time\n",
    "for i in range(1, len(transform_columns) + 1):\n",
    "    # Determine the original columns to include up to this iteration\n",
    "    included_columns = transform_columns[:i]\n",
    "\n",
    "    # Find the corresponding new columns from the transformation\n",
    "    included_new_cols = [col for col in x_transformed.columns if col.split('_')[0] in included_columns]\n",
    "\n",
    "    # Construct the final datasets for this iteration\n",
    "    x_final = pd.concat([x.drop(non_num_columns + ['salary', 'fnlwgt'], axis=1), x_transformed[included_new_cols]], axis=1)\n",
    "    xt_final = pd.concat([xt.drop(non_num_columns + ['salary', 'fnlwgt'], axis=1), xt_transformed[included_new_cols]], axis=1)\n",
    "\n",
    "    # Fit the models\n",
    "    dt_classifier.fit(x_final.drop(['salary_encoded'], axis=1), x_final['salary_encoded'])\n",
    "    rf_classifier.fit(x_final.drop(['salary_encoded'], axis=1), x_final['salary_encoded'])\n",
    "\n",
    "    # Make predictions\n",
    "    pred_dt = dt_classifier.predict(xt_final.drop(['salary_encoded'], axis=1))\n",
    "    pred_rf = rf_classifier.predict(xt_final.drop(['salary_encoded'], axis=1))\n",
    "\n",
    "    # Evaluate and print the results\n",
    "    print(f\"Iteration {i}: Using numerical columns and {included_columns}\")\n",
    "    print(\"Decision Tree Accuracy Score:\", accuracy_score(xt_final['salary_encoded'], pred_dt))\n",
    "    print(\"Random Forest Accuracy Score:\", accuracy_score(xt_final['salary_encoded'], pred_rf))\n",
    "    print(\"\\nDecision Tree Confusion Matrix:\")\n",
    "    print(confusion_matrix(xt_final['salary_encoded'], pred_dt))\n",
    "    print(\"Random Forest Confusion Matrix:\")\n",
    "    print(confusion_matrix(xt_final['salary_encoded'], pred_rf))\n",
    "    print(\"\\nDecision Tree Classification Report:\")\n",
    "    print(classification_report(xt_final['salary_encoded'], pred_dt))\n",
    "    print(\"Random Forest Classification Report:\")\n",
    "    print(classification_report(xt_final['salary_encoded'], pred_rf))\n",
    "    print(\"--------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
